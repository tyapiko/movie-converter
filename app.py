import streamlit as st
import tempfile
import os
from moviepy import VideoFileClip, AudioFileClip, CompositeAudioClip, concatenate_videoclips
from PIL import Image, ImageDraw, ImageFont
import numpy as np
import cv2
from pptx import Presentation
import io

# âœ… å®Ÿé¨“å®Œäº†: GitHub ActionsãŒæ§‹æ–‡ã‚¨ãƒ©ãƒ¼ã‚’æ­£å¸¸ã«æ¤œå‡ºã—ã¾ã—ãŸ

st.set_page_config(
    page_title="å‹•ç”»ç·¨é›†ãƒ„ãƒ¼ãƒ«",
    page_icon="ğŸ¬",
    layout="wide"
)

# ã‚µã‚¤ãƒ‰ãƒãƒ¼ã§ãƒ„ãƒ¼ãƒ«é¸æŠ
st.sidebar.title("ğŸ› ï¸ ãƒ„ãƒ¼ãƒ«é¸æŠ")
tool = st.sidebar.radio(
    "ä½¿ç”¨ã™ã‚‹ãƒ„ãƒ¼ãƒ«",
    ["ã‚·ãƒ§ãƒ¼ãƒˆå‹•ç”»å¤‰æ›", "å‹•ç”»çµåˆ", "ãƒ‘ãƒ¯ãƒãƒŠãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³å‹•ç”»"]
)

if tool == "ã‚·ãƒ§ãƒ¼ãƒˆå‹•ç”»å¤‰æ›":
    st.title("ğŸ¬ ã‚·ãƒ§ãƒ¼ãƒˆå‹•ç”»ã‚³ãƒ³ãƒãƒ¼ã‚¿ãƒ¼8")
    st.markdown("å‹•ç”»ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ã€YouTubeã‚·ãƒ§ãƒ¼ãƒˆå‘ã‘ã®ç¸¦å‹å‹•ç”»ã«å¤‰æ›ã—ã¾ã—ã‚‡ã†ï¼")
elif tool == "å‹•ç”»çµåˆ":
    st.title("ğŸ”— å‹•ç”»çµåˆãƒ„ãƒ¼ãƒ«")
    st.markdown("è¤‡æ•°ã®ã‚·ãƒ§ãƒ¼ãƒˆå‹•ç”»ã‚’é¸æŠã—ã¦ã€é•·æ™‚é–“å‹•ç”»ã«çµåˆã—ã¾ã—ã‚‡ã†ï¼")
else:  # ãƒ‘ãƒ¯ãƒãƒŠãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³å‹•ç”»
    st.title("ğŸ“Š ãƒ‘ãƒ¯ãƒãƒŠãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³å‹•ç”»")
    st.markdown("PowerPointãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ã€ãƒãƒ¼ãƒˆéƒ¨åˆ†ã‚’èª­ã¿ä¸Šã’ã‚‹å‹•ç”»ã‚’ä½œæˆã—ã¾ã—ã‚‡ã†ï¼")

def resize_video_to_shorts(video_path, output_path, scale_factor=1.0, start_time=None, end_time=None, keep_original_size=False):
    """å‹•ç”»ã‚’YouTubeã‚·ãƒ§ãƒ¼ãƒˆå½¢å¼(9:16)ã«ãƒªã‚µã‚¤ã‚ºã€ã¾ãŸã¯å…ƒã®ã‚µã‚¤ã‚ºã‚’ç¶­æŒ"""
    import subprocess
    
    # FFmpegã‚³ãƒãƒ³ãƒ‰ã§å‹•ç”»å¤‰æ›
    ffmpeg_cmd = ['ffmpeg', '-i', video_path]
    
    # ãƒˆãƒªãƒŸãƒ³ã‚°ãŒæŒ‡å®šã•ã‚Œã¦ã„ã‚‹å ´åˆ
    if start_time is not None and end_time is not None:
        ffmpeg_cmd.extend(['-ss', str(start_time), '-t', str(end_time - start_time)])

    if not keep_original_size:
        # å…ƒã®å‹•ç”»æƒ…å ±ã‚’å–å¾—
        clip = VideoFileClip(video_path)
        original_width, original_height = clip.size
        original_ratio = original_width / original_height
        clip.close()
        
        # YouTubeã‚·ãƒ§ãƒ¼ãƒˆã®æ¨å¥¨è§£åƒåº¦: 1080x1920 (9:16)
        target_width = 1080
        target_height = 1920
        target_ratio = target_width / target_height
        
        # åŸºæœ¬ã‚¹ã‚±ãƒ¼ãƒ«è¨ˆç®—ï¼ˆã‚¿ãƒ¼ã‚²ãƒƒãƒˆæ ã«åã¾ã‚‹ã‚µã‚¤ã‚ºï¼‰
        if original_ratio > target_ratio:
            # æ¨ªé•·ã®å ´åˆã€å¹…ã‚’ã‚¿ãƒ¼ã‚²ãƒƒãƒˆå¹…ã«åˆã‚ã›ã‚‹
            base_width = target_width
            base_height = int(target_width / original_ratio)
        else:
            # ç¸¦é•·ã®å ´åˆã€é«˜ã•ã‚’ã‚¿ãƒ¼ã‚²ãƒƒãƒˆé«˜ã•ã«åˆã‚ã›ã‚‹
            base_height = target_height
            base_width = int(target_height * original_ratio)
        
        # scale_factorã‚’é©ç”¨ï¼ˆæ‹¡å¤§å€ç‡ã«ã‚ˆã‚‹èª¿æ•´ï¼‰
        final_width = int(base_width * scale_factor)
        final_height = int(base_height * scale_factor)
        
        # æ‹¡å¤§å€ç‡ãŒ1.0ã‚ˆã‚Šå¤§ãã„å ´åˆã€å‹•ç”»ãŒã‚¿ãƒ¼ã‚²ãƒƒãƒˆãƒ•ãƒ¬ãƒ¼ãƒ ã‹ã‚‰ã¯ã¿å‡ºã™ã®ã¯æ­£å¸¸
        # ãƒ‘ãƒ‡ã‚£ãƒ³ã‚°ã‚¨ãƒ©ãƒ¼ã‚’é¿ã‘ã‚‹ãŸã‚ã€æœ€å°ã‚µã‚¤ã‚ºã¯1ãƒ”ã‚¯ã‚»ãƒ«ä»¥ä¸Šã‚’ä¿è¨¼
        final_width = max(1, final_width)
        final_height = max(1, final_height)
        
        # ãƒ“ãƒ‡ã‚ªãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ã‚’æ§‹ç¯‰
        if scale_factor > 1.0:
            # æ‹¡å¤§æ™‚ï¼šã‚¹ã‚±ãƒ¼ãƒ«â†’ä¸­å¤®ã‚¯ãƒ­ãƒƒãƒ—â†’ãƒ‘ãƒ‡ã‚£ãƒ³ã‚°
            vf = f'scale={final_width}:{final_height},crop={min(final_width, target_width)}:{min(final_height, target_height)},pad={target_width}:{target_height}:(ow-iw)/2:(oh-ih)/2:black'
        else:
            # ç¸®å°æ™‚ï¼šã‚¹ã‚±ãƒ¼ãƒ«â†’ãƒ‘ãƒ‡ã‚£ãƒ³ã‚°
            vf = f'scale={final_width}:{final_height},pad={target_width}:{target_height}:(ow-iw)/2:(oh-ih)/2:black'
        
        ffmpeg_cmd.extend([
            '-vf', vf
        ])
    
    ffmpeg_cmd.extend([
        '-c:v', 'libx264',
        '-c:a', 'aac',
        '-b:v', '8000k',
        '-crf', '18',
        '-preset', 'slow',
        '-y',  # overwrite output file
        output_path
    ])
    
    try:
        subprocess.run(ffmpeg_cmd, check=True, capture_output=True)
        return output_path
    except subprocess.CalledProcessError as e:
        raise Exception(f"FFmpegå‡¦ç†ã§ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e.stderr.decode()}")
    except FileNotFoundError:
        raise Exception("FFmpegãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚ã‚·ã‚¹ãƒ†ãƒ ã«FFmpegãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ã‚‹ã“ã¨ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")

def get_voicevox_url():
    """VOICEVOXæ¥ç¶šURLã‚’å–å¾—ï¼ˆç’°å¢ƒå¤‰æ•°ã‚’å„ªå…ˆï¼‰"""
    import os
    
    # ç’°å¢ƒå¤‰æ•°ã‹ã‚‰å–å¾—ï¼ˆDockerç’°å¢ƒã§è¨­å®šï¼‰
    voicevox_url = os.getenv('VOICEVOX_URL')
    if voicevox_url:
        return voicevox_url
    
    # Docker Composeç’°å¢ƒã§ã¯ voicevox ã‚µãƒ¼ãƒ“ã‚¹åã§æ¥ç¶š
    try:
        # Dockerç’°å¢ƒã‹ãƒã‚§ãƒƒã‚¯
        if os.path.exists('/.dockerenv'):
            return "http://voicevox:50021"
    except:
        pass
    
    # WSLç’°å¢ƒã®å ´åˆã¯Windowsãƒ›ã‚¹ãƒˆIPã‚’å–å¾—
    try:
        with open('/etc/resolv.conf', 'r') as f:
            for line in f:
                if line.startswith('nameserver'):
                    host_ip = line.split()[1]
                    return f"http://{host_ip}:50021"
    except:
        pass
    
    # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: localhost
    return "http://localhost:50021"

def generate_voice_with_voicevox(text, speaker_id=10, output_path=None):
    """VOICEVOXã‚’ä½¿ç”¨ã—ã¦éŸ³å£°ã‚’ç”Ÿæˆï¼ˆé›¨æ™´ã¯ã†: speaker_id=10ï¼‰"""
    import requests
    import json
    import tempfile
    
    if output_path is None:
        output_path = tempfile.mktemp(suffix='.wav')
    
    # ç’°å¢ƒã«é©ã—ãŸVOICEVOX URLã‚’å–å¾—
    base_url = get_voicevox_url()
    
    try:
        # VOICEVOXã‚¨ãƒ³ã‚¸ãƒ³ã®èµ·å‹•ç¢ºèª
        response = requests.get(f"{base_url}/speakers", timeout=5)
        if response.status_code != 200:
            raise Exception(f"VOICEVOXã‚¨ãƒ³ã‚¸ãƒ³ãŒèµ·å‹•ã—ã¦ã„ã¾ã›ã‚“ (æ¥ç¶šå…ˆ: {base_url})")
        
        # éŸ³éŸ¿ç‰¹å¾´é‡ã®ç”Ÿæˆ
        query_response = requests.post(
            f"{base_url}/audio_query?text={text}&speaker={speaker_id}",
            timeout=10
        )
        query_response.raise_for_status()
        query_data = query_response.json()
        
        # éŸ³å£°åˆæˆ
        synthesis_response = requests.post(
            f"{base_url}/synthesis?speaker={speaker_id}",
            headers={"Content-Type": "application/json"},
            data=json.dumps(query_data),
            timeout=30
        )
        synthesis_response.raise_for_status()
        
        # éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä¿å­˜
        with open(output_path, 'wb') as f:
            f.write(synthesis_response.content)
        
        return output_path
        
    except requests.exceptions.RequestException as e:
        raise Exception(f"VOICEVOXã¨ã®é€šä¿¡ã«å¤±æ•—ã—ã¾ã—ãŸ (æ¥ç¶šå…ˆ: {base_url}): {str(e)}")
    except Exception as e:
        raise Exception(f"éŸ³å£°ç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸ: {str(e)}")

def add_multiple_voices_to_video(video_path, output_path, voices, original_volume=1.0):
    """å‹•ç”»ã«è¤‡æ•°ã®éŸ³å£°ã‚’è¿½åŠ ï¼ˆFFmpegç›´æ¥å®Ÿè¡Œç‰ˆï¼‰"""
    import subprocess
    import tempfile
    
    print(f"DEBUG: FFmpegç›´æ¥å®Ÿè¡Œç‰ˆã§éŸ³å£°è¿½åŠ é–‹å§‹")
    
    temp_voice_files = []
    try:
        # VOICEVOXéŸ³å£°ã‚’ç”Ÿæˆ
        voice_files = []
        for voice in voices:
            try:
                voice_path = generate_voice_with_voicevox(voice['text'])
                temp_voice_files.append(voice_path)
                voice_files.append({
                    'path': voice_path,
                    'start_time': voice['start_time'],
                    'volume': voice['volume']
                })
            except Exception as e:
                st.warning(f"âš ï¸ éŸ³å£°ã€Œ{voice['text'][:20]}...ã€ã®ç”Ÿæˆã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã—ãŸ: {str(e)}")
                continue
        
        if not voice_files:
            # éŸ³å£°è¿½åŠ ãŒãªã„å ´åˆã¯å…ƒå‹•ç”»ã‚’ãã®ã¾ã¾ã‚³ãƒ”ãƒ¼
            import shutil
            shutil.copy2(video_path, output_path)
            return output_path
        
        # FFmpegã‚³ãƒãƒ³ãƒ‰ã‚’æ§‹ç¯‰ï¼ˆå‹•ç”»ã‚¹ãƒˆãƒªãƒ¼ãƒ ã¯ã‚³ãƒ”ãƒ¼ã€éŸ³å£°ã®ã¿å‡¦ç†ï¼‰
        ffmpeg_cmd = ['ffmpeg', '-i', video_path, '-y']
        
        # å„éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å…¥åŠ›ã¨ã—ã¦è¿½åŠ 
        for voice_file in voice_files:
            ffmpeg_cmd.extend(['-i', voice_file['path']])
        
        # ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼æ§‹ç¯‰ï¼ˆã‚·ãƒ³ãƒ—ãƒ«ã«éŸ³å£°ã‚’ãƒŸãƒƒã‚¯ã‚¹ï¼‰
        if len(voice_files) == 1:
            # 1ã¤ã®éŸ³å£°ã®ã¿
            voice = voice_files[0]
            delay_ms = int(voice['start_time'] * 1000)  # ãƒŸãƒªç§’ã«å¤‰æ›
            if delay_ms > 0:
                audio_filter = f'[1:a]volume={voice["volume"]},adelay={delay_ms}[voice];[0:a][voice]amix=inputs=2:duration=first[audio]'
            else:
                audio_filter = f'[1:a]volume={voice["volume"]}[voice];[0:a][voice]amix=inputs=2:duration=first[audio]'
        else:
            # è¤‡æ•°éŸ³å£°ã‚’ãƒŸãƒƒã‚¯ã‚¹
            voice_filters = []
            for i, voice in enumerate(voice_files):
                delay_ms = int(voice['start_time'] * 1000)  # ãƒŸãƒªç§’ã«å¤‰æ›
                if delay_ms > 0:
                    voice_filters.append(f'[{i+1}:a]volume={voice["volume"]},adelay={delay_ms}[voice{i}]')
                else:
                    voice_filters.append(f'[{i+1}:a]volume={voice["volume"]}[voice{i}]')
            
            # å…¨éŸ³å£°ã‚’ãƒŸãƒƒã‚¯ã‚¹
            voice_labels = ''.join(f'[voice{i}]' for i in range(len(voice_files)))
            audio_filter = ';'.join(voice_filters) + f';[0:a]{voice_labels}amix=inputs={len(voice_files)+1}:duration=first[audio]'
        
        # å‹•ç”»ã‚¹ãƒˆãƒªãƒ¼ãƒ ã¯ã‚³ãƒ”ãƒ¼ã€éŸ³å£°ã®ã¿å‡¦ç†
        ffmpeg_cmd.extend([
            '-filter_complex', audio_filter,
            '-map', '0:v',  # å‹•ç”»ã‚¹ãƒˆãƒªãƒ¼ãƒ ã¯ãã®ã¾ã¾ã‚³ãƒ”ãƒ¼
            '-map', '[audio]',  # å‡¦ç†ã•ã‚ŒãŸéŸ³å£°
            '-c:v', 'copy',  # å‹•ç”»ã¯å†ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ã—ãªã„ï¼ˆé‡è¦ï¼ï¼‰
            '-c:a', 'aac',
            output_path
        ])
        
        print(f"DEBUG: FFmpegå®Ÿè¡Œ: {' '.join(ffmpeg_cmd)}")
        result = subprocess.run(ffmpeg_cmd, capture_output=True, text=True)
        
        if result.returncode != 0:
            print(f"DEBUG: FFmpeg ã‚¨ãƒ©ãƒ¼: {result.stderr}")
            raise Exception(f"FFmpegå‡¦ç†ã«å¤±æ•—ã—ã¾ã—ãŸ: {result.stderr}")
        
        print(f"DEBUG: FFmpegæˆåŠŸ")
        
    finally:
        # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«å‰Šé™¤
        for temp_file in temp_voice_files:
            try:
                os.unlink(temp_file)
            except:
                pass
    
    return output_path


def add_bgm_to_video(video_path, output_path, bgm_path=None, bgm_volume=0.5, original_volume=1.0, loop_bgm=True, bgm_start_time=0.0):
    """å‹•ç”»ã«BGMã‚’è¿½åŠ ï¼ˆFFmpegã‚’ä½¿ç”¨ã—ã¦ã‚ˆã‚Šæ­£ç¢ºã«ï¼‰"""
    import subprocess
    import tempfile
    
    print(f"DEBUG BGM: FFmpegæ–¹å¼ã§BGMè¿½åŠ é–‹å§‹")
    
    # å…ƒã®å‹•ç”»ã®æƒ…å ±ã‚’å–å¾—
    clip = VideoFileClip(video_path)
    original_video_duration = clip.duration
    original_fps = clip.fps
    print(f"DEBUG BGM: å…ƒã®å‹•ç”» - é•·ã•: {original_video_duration}ç§’, FPS: {original_fps}")
    clip.close()
    
    if bgm_path and os.path.exists(bgm_path):
        try:
            # FFmpegã§BGMã‚’è¿½åŠ 
            bgm_info = AudioFileClip(bgm_path)
            bgm_duration = bgm_info.duration
            bgm_info.close()
            
            ffmpeg_cmd = ['ffmpeg', '-i', video_path, '-i', bgm_path, '-y']
            
            # ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼æ§‹ç¯‰
            filter_parts = []
            
            # å‹•ç”»ãƒˆãƒ©ãƒƒã‚¯
            filter_parts.append('[0:v]copy[video]')
            
            # BGMå‡¦ç†
            if loop_bgm and bgm_duration < original_video_duration:
                # ãƒ«ãƒ¼ãƒ—ãŒå¿…è¦ãªå ´åˆ
                loops_needed = int(original_video_duration / bgm_duration) + 1
                filter_parts.append(f'[1:a]stream_loop={loops_needed},atrim=0:{original_video_duration},volume={bgm_volume}[bgm]')
            else:
                # ãƒ«ãƒ¼ãƒ—ä¸è¦ã¾ãŸã¯BGMãŒååˆ†é•·ã„å ´åˆ
                filter_parts.append(f'[1:a]atrim=0:{original_video_duration},volume={bgm_volume}[bgm]')
            
            # BGMã®é–‹å§‹æ™‚é–“èª¿æ•´
            if bgm_start_time > 0.0:
                delay_ms = int(bgm_start_time * 1000)
                filter_parts[-1] = f'[1:a]atrim=0:{original_video_duration},adelay={delay_ms}|{delay_ms},volume={bgm_volume}[bgm]'
            
            # å…ƒã®éŸ³å£°ãŒã‚ã‚‹å ´åˆã¯ãƒŸãƒƒã‚¯ã‚¹
            if VideoFileClip(video_path).audio is not None:
                filter_parts.append(f'[0:a]volume={original_volume}[orig]')
                filter_parts.append('[orig][bgm]amix=inputs=2:duration=first[audio]')
            else:
                filter_parts.append('[bgm]acopy[audio]')
            
            # ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ã‚°ãƒ©ãƒ•ã‚’å®Œæˆ
            filter_complex = ';'.join(filter_parts)
            ffmpeg_cmd.extend([
                '-filter_complex', filter_complex,
                '-map', '[video]',
                '-map', '[audio]',
                '-t', str(original_video_duration),
                '-r', str(original_fps),
                '-c:v', 'libx264',
                '-c:a', 'aac',
                '-crf', '18',
                '-preset', 'slow',
                output_path
            ])
            
            print(f"DEBUG BGM: FFmpegå®Ÿè¡Œ: {' '.join(ffmpeg_cmd)}")
            result = subprocess.run(ffmpeg_cmd, capture_output=True, text=True)
            
            if result.returncode == 0:
                print(f"DEBUG BGM: FFmpegæˆåŠŸ")
                return output_path
            else:
                print(f"DEBUG BGM: FFmpeg ã‚¨ãƒ©ãƒ¼: {result.stderr}")
                # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å‡¦ç†ã¸ç¶šè¡Œ
                
        except Exception as e:
            print(f"DEBUG BGM: FFmpegæ–¹å¼å¤±æ•—: {str(e)}")
            # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å‡¦ç†ã¸ç¶šè¡Œ
        
        # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼šMoviePyæ–¹å¼
        print("DEBUG BGM: MoviePyãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯æ–¹å¼ã‚’ä½¿ç”¨")
        clip = VideoFileClip(video_path)
        bgm = AudioFileClip(bgm_path)
        
        # BGMã®éŸ³é‡ã‚’èª¿æ•´
        bgm = bgm.with_fps(44100)
        if bgm_volume != 1.0:
            bgm = bgm.with_volume_scaled(bgm_volume)
        
        # BGMã‚’ãƒ«ãƒ¼ãƒ—å†ç”Ÿã™ã‚‹ã‹ã©ã†ã‹
        if loop_bgm and bgm.duration < original_video_duration:
            # BGMã‚’ãƒ«ãƒ¼ãƒ—ã—ã¦å‹•ç”»ã®é•·ã•ã«åˆã‚ã›ã‚‹
            loops_needed = int(clip.duration / bgm.duration) + 1
            try:
                # ãƒ«ãƒ¼ãƒ—å‡¦ç†ã‚’è¡Œã„ã€å‹•ç”»ã®é•·ã•ã«åˆã‚ã›ã¦ã‚«ãƒƒãƒˆ
                bgm = bgm.audio_loop(n=loops_needed).subclipped(0, clip.duration)
            except Exception as e:
                # ãƒ«ãƒ¼ãƒ—å‡¦ç†ã«å¤±æ•—ã—ãŸå ´åˆã¯ã€å˜ç´”ã«ç¹°ã‚Šè¿”ã—å†ç”Ÿ
                bgm_list = []
                current_duration = 0
                while current_duration < clip.duration:
                    remaining_duration = clip.duration - current_duration
                    if remaining_duration >= bgm.duration:
                        bgm_list.append(bgm)
                        current_duration += bgm.duration
                    else:
                        bgm_list.append(bgm.subclipped(0, remaining_duration))
                        current_duration += remaining_duration
                
                if bgm_list:
                    bgm = concatenate_audioclips(bgm_list)
                else:
                    bgm = bgm.subclipped(0, min(bgm.duration, clip.duration))
        else:
            # BGMã‚’å‹•ç”»ã®é•·ã•ã«åˆã‚ã›ã¦ã‚«ãƒƒãƒˆ
            bgm = bgm.subclipped(0, min(bgm.duration, clip.duration))
        
        # BGMã®é–‹å§‹æ™‚é–“ã‚’é©ç”¨
        if bgm_start_time > 0.0 and bgm_start_time < clip.duration:
            # ç„¡éŸ³ã®éŸ³å£°ã‚’ä½œæˆã—ã¦BGMã®å‰ã«è¿½åŠ 
            silence_duration = min(bgm_start_time, clip.duration)
            remaining_duration = clip.duration - silence_duration
            
            if remaining_duration > 0:
                # BGMã‚’æ®‹ã‚Šæ™‚é–“ã«åˆã‚ã›ã¦ã‚«ãƒƒãƒˆ
                bgm = bgm.subclipped(0, min(bgm.duration, remaining_duration))
                # ç„¡éŸ³ã¨BGMã‚’çµåˆ
                bgm = bgm.with_start(bgm_start_time)
            else:
                # é–‹å§‹æ™‚é–“ãŒå‹•ç”»ã®é•·ã•ã‚’è¶…ãˆã¦ã„ã‚‹å ´åˆã¯ç„¡éŸ³
                bgm = None
        
        # å…ƒã®éŸ³å£°ãŒã‚ã‚‹ã‹ãƒã‚§ãƒƒã‚¯
        if clip.audio is not None:
            # å…ƒã®éŸ³å£°ã®éŸ³é‡ã‚’èª¿æ•´
            original_audio = clip.audio
            if original_volume != 1.0:
                original_audio = original_audio.with_volume_scaled(original_volume)
            # BGMã¨å…ƒã®éŸ³å£°ã‚’åˆæˆ
            if bgm is not None:
                final_audio = CompositeAudioClip([original_audio, bgm])
            else:
                final_audio = original_audio
        else:
            # å…ƒã®éŸ³å£°ãŒãªã„å ´åˆã¯BGMã®ã¿
            if bgm is not None:
                final_audio = bgm
            else:
                final_audio = None
        
        # å‹•ç”»ã«éŸ³å£°ã‚’è¨­å®šï¼ˆãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¬ãƒ¼ãƒˆã‚’ç¶­æŒï¼‰
        if final_audio is not None:
            # éŸ³å£°ã®é•·ã•ã‚’å‹•ç”»ã®é•·ã•ã«åˆã‚ã›ã‚‹
            if final_audio.duration > original_video_duration:
                final_audio = final_audio.subclipped(0, original_video_duration)
            elif final_audio.duration < original_video_duration:
                final_audio = final_audio.with_duration(original_video_duration)
            
            # é‡è¦ï¼šå…ƒã®å‹•ç”»ã®FPSã‚’ä¿æŒ
            final_clip = clip.with_audio(final_audio).with_fps(original_fps)
        else:
            final_clip = clip.with_fps(original_fps)
        
        # å‹•ç”»ã®é•·ã•ã‚’ç¢ºå®Ÿã«è¨­å®š
        final_clip = final_clip.with_duration(original_video_duration)
        
        # å‡ºåŠ›ï¼ˆå…ƒã®FPSã‚’æ˜ç¤ºçš„ã«æŒ‡å®šï¼‰
        final_clip.write_videofile(
            output_path,
            codec='libx264',
            audio_codec='aac',
            bitrate='8000k',
            fps=original_fps,  # é‡è¦ï¼šå…ƒã®FPSã‚’æ˜ç¤ºçš„ã«æŒ‡å®š
            ffmpeg_params=['-crf', '18', '-preset', 'slow']
        )
        
        # ãƒªã‚½ãƒ¼ã‚¹ã‚’ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
        clip.close()
        bgm.close()
        final_clip.close()
        if clip.audio is not None:
            original_audio.close()
        final_audio.close()
    else:
        # BGMãŒãªã„å ´åˆã¯å…ƒã®å‹•ç”»ã‚’ãã®ã¾ã¾ã‚³ãƒ”ãƒ¼ï¼ˆFPSã‚’ä¿æŒï¼‰
        clip = VideoFileClip(video_path)
        final_clip = clip.with_fps(original_fps).with_duration(original_video_duration)
        final_clip.write_videofile(
            output_path,
            codec='libx264',
            audio_codec='aac',
            bitrate='8000k',
            fps=original_fps,
            ffmpeg_params=['-crf', '18', '-preset', 'slow']
        )
        clip.close()
        final_clip.close()
    
    return output_path

def add_text_to_video(video_path, output_path, telops, font_size=60):
    """å‹•ç”»ã«æ™‚é–“ãƒ™ãƒ¼ã‚¹ã®ãƒ†ã‚­ã‚¹ãƒˆã‚ªãƒ¼ãƒãƒ¼ãƒ¬ã‚¤ã‚’è¿½åŠ """
    import cv2
    import numpy as np
    from PIL import Image, ImageDraw, ImageFont
    
    # OpenCVã¨Pillowã‚’ä½¿ç”¨ã—ã¦ãƒ†ã‚­ã‚¹ãƒˆã‚’è¿½åŠ 
    clip = VideoFileClip(video_path)
    
    def add_text_frame(get_frame, t):
        frame = get_frame(t)
        # numpyé…åˆ—ã‚’PIL Imageã«å¤‰æ›
        img = Image.fromarray(frame.astype('uint8'))
        draw = ImageDraw.Draw(img)
        
        # æ—¥æœ¬èªå¯¾å¿œãƒ•ã‚©ãƒ³ãƒˆã‚’å„ªå…ˆçš„ã«ä½¿ç”¨
        japanese_fonts = [
            "/usr/share/fonts/opentype/noto/NotoSansCJK-Bold.ttc",
            "/usr/share/fonts/opentype/noto/NotoSansCJK-Regular.ttc",
            "fonts/NotoSansJP-Regular.ttf",
            "NotoSansCJK-Regular.ttc"
        ]
        
        font = None
        for font_path in japanese_fonts:
            try:
                font = ImageFont.truetype(font_path, font_size)
                break
            except:
                continue
        
        if font is None:
            try:
                font = ImageFont.load_default(size=font_size)
            except:
                font = ImageFont.load_default()
        
        # ç¾åœ¨ã®æ™‚é–“ã«è¡¨ç¤ºã™ã¹ããƒ†ãƒ­ãƒƒãƒ—ã‚’æç”»
        for telop in telops:
            # æ™‚é–“ç¯„å›²å†…ã‹ãƒã‚§ãƒƒã‚¯
            if telop['start_time'] <= t <= telop['end_time']:
                text = telop['text']
                position = telop['position']
                
                if not text:  # ç©ºã®ãƒ†ã‚­ã‚¹ãƒˆã¯ã‚¹ã‚­ãƒƒãƒ—
                    continue
                    
                # ãƒ†ã‚­ã‚¹ãƒˆã‚µã‚¤ã‚ºã‚’å–å¾—
                bbox = draw.textbbox((0, 0), text, font=font)
                text_width = bbox[2] - bbox[0]
                text_height = bbox[3] - bbox[1]
                
                # ä½ç½®ã‚’è¨ˆç®—ï¼ˆä¸­å¤®å¯„ã‚Šã«èª¿æ•´ï¼‰
                if position == "top":
                    x = (img.width - text_width) // 2
                    y = img.height // 4 - text_height // 2  # ä¸­å¤®å¯„ã‚Šã®ä¸Š
                elif position == "bottom":
                    x = (img.width - text_width) // 2
                    y = img.height * 3 // 4 - text_height // 2  # ä¸­å¤®å¯„ã‚Šã®ä¸‹
                else:  # center
                    x = (img.width - text_width) // 2
                    y = (img.height - text_height) // 2
                
                # ãƒ†ãƒ­ãƒƒãƒ—ã®è‰²è¨­å®šï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã¯ç™½ï¼‰
                text_color = telop.get('color', (255, 255, 255))
                
                # ãƒ†ã‚­ã‚¹ãƒˆã‚’æç”»ï¼ˆå½±ä»˜ãï¼‰
                draw.text((x+2, y+2), text, font=font, fill=(0, 0, 0))  # å½±
                draw.text((x, y), text, font=font, fill=text_color)  # ãƒ†ã‚­ã‚¹ãƒˆ
        
        return np.array(img)
    
    # ãƒ†ã‚­ã‚¹ãƒˆä»˜ãã®å‹•ç”»ã‚’ä½œæˆ
    final_video = clip.transform(add_text_frame)
    
    # å‡ºåŠ›ï¼ˆé«˜ç”»è³ªè¨­å®šï¼‰
    final_video.write_videofile(
        output_path, 
        codec='libx264', 
        audio_codec='aac',
        bitrate='8000k',  # é«˜ãƒ“ãƒƒãƒˆãƒ¬ãƒ¼ãƒˆ
        ffmpeg_params=['-crf', '18', '-preset', 'slow']  # é«˜ç”»è³ªãƒ»ä½åœ§ç¸®
    )
    clip.close()
    final_video.close()
    
    return output_path

def extract_slides_and_notes(pptx_file):
    """PowerPointãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ã‚¹ãƒ©ã‚¤ãƒ‰ã¨ speaker notes ã‚’æŠ½å‡º"""
    presentation = Presentation(pptx_file)
    slides_data = []
    
    for i, slide in enumerate(presentation.slides):
        # ã‚¹ãƒ©ã‚¤ãƒ‰ã‚’ç”»åƒã¨ã—ã¦ä¿å­˜
        slide_image_path = tempfile.mktemp(suffix=f'_slide_{i}.png')
        
        # ã‚¹ãƒ©ã‚¤ãƒ‰ã®ç”»åƒã‚’å–å¾—ã™ã‚‹ãŸã‚ã€ã¾ãšPILã§ç©ºã®ç”»åƒã‚’ä½œæˆ
        # æ³¨æ„: python-pptxã¯ã‚¹ãƒ©ã‚¤ãƒ‰ã®ç›´æ¥çš„ãªç”»åƒå¤‰æ›ã‚’ã‚µãƒãƒ¼ãƒˆã—ã¦ã„ãªã„ãŸã‚ã€
        # ã“ã“ã§ã¯ã‚¹ãƒ©ã‚¤ãƒ‰ã®ãƒ†ã‚­ã‚¹ãƒˆå†…å®¹ã¨ãƒãƒ¼ãƒˆã®ã¿ã‚’æŠ½å‡ºã—ã¾ã™
        
        # ã‚¹ãƒ©ã‚¤ãƒ‰ã®ãƒ†ã‚­ã‚¹ãƒˆå†…å®¹ã‚’å–å¾—
        slide_text = ""
        for shape in slide.shapes:
            if hasattr(shape, "text"):
                slide_text += shape.text + " "
        
        # ã‚¹ãƒ”ãƒ¼ã‚«ãƒ¼ãƒãƒ¼ãƒˆã‚’å–å¾—
        notes_slide = slide.notes_slide
        notes_text = ""
        if notes_slide:
            notes_text_frame = notes_slide.notes_text_frame
            if notes_text_frame:
                notes_text = notes_text_frame.text
        
        slides_data.append({
            'slide_number': i + 1,
            'slide_text': slide_text.strip(),
            'notes_text': notes_text.strip(),
            'slide_image_path': None  # å®Ÿéš›ã®ç”»åƒæŠ½å‡ºã¯åˆ¥ã®æ–¹æ³•ã§å®Ÿè£…
        })
    
    return slides_data

def create_slide_images_from_pptx(pptx_file):
    """PowerPointã‚¹ãƒ©ã‚¤ãƒ‰ã‚’ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ã«å¤‰æ›ã™ã‚‹ï¼ˆLibreOfficeã‚’ä½¿ç”¨ï¼‰"""
    import subprocess
    import shutil
    
    # ä¸€æ™‚ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ä½œæˆ
    temp_dir = tempfile.mkdtemp()
    pptx_path = os.path.join(temp_dir, "presentation.pptx")
    
    # ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä¿å­˜
    with open(pptx_path, 'wb') as f:
        pptx_file.seek(0)
        f.write(pptx_file.read())
    
    try:
        # LibreOfficeã§PDFã«å¤‰æ›
        cmd = [
            'libreoffice', 
            '--headless', 
            '--convert-to', 'pdf',
            '--outdir', temp_dir,
            pptx_path
        ]
        result = subprocess.run(cmd, capture_output=True, text=True, timeout=120)
        
        if result.returncode != 0:
            raise Exception(f"LibreOfficeå¤‰æ›ã‚¨ãƒ©ãƒ¼: {result.stderr}")
        
        # PDFã‚’PNGç”»åƒã«å¤‰æ›ï¼ˆpdftoppmã‚’ä½¿ç”¨ - ã‚ˆã‚Šå®‰å®šï¼‰
        pdf_path = os.path.join(temp_dir, "presentation.pdf")
        if not os.path.exists(pdf_path):
            raise Exception("PDFå¤‰æ›ã«å¤±æ•—ã—ã¾ã—ãŸ")
        
        # pdftoppmã§PDFã®å„ãƒšãƒ¼ã‚¸ã‚’PNGã«å¤‰æ›
        cmd = [
            'pdftoppm',
            '-png',
            '-r', '150',  # è§£åƒåº¦150dpi
            pdf_path,
            os.path.join(temp_dir, 'slide')
        ]
        result = subprocess.run(cmd, capture_output=True, text=True, timeout=120)
        
        if result.returncode != 0:
            # pdftoppmãŒå¤±æ•—ã—ãŸå ´åˆã¯ImageMagickã‚’è©¦è¡Œ
            cmd = [
                'convert',
                '-density', '150',
                '-background', 'white',
                '-alpha', 'remove',
                '-quality', '90',
                pdf_path,
                os.path.join(temp_dir, 'slide-%03d.png')
            ]
            result = subprocess.run(cmd, capture_output=True, text=True, timeout=120)
            
            if result.returncode != 0:
                raise Exception(f"ç”»åƒå¤‰æ›ã‚¨ãƒ©ãƒ¼: {result.stderr}")
        
        # ç”Ÿæˆã•ã‚ŒãŸç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã‚’å–å¾—
        slide_images = []
        
        # pdftoppmã®å‡ºåŠ›å½¢å¼ã«å¯¾å¿œ
        for file in sorted(os.listdir(temp_dir)):
            if file.startswith('slide') and file.endswith('.png'):
                image_path = os.path.join(temp_dir, file)
                if os.path.exists(image_path):
                    # æ°¸ç¶šçš„ãªå ´æ‰€ã«ã‚³ãƒ”ãƒ¼
                    slide_num = len(slide_images)
                    permanent_path = tempfile.mktemp(suffix=f'_slide_{slide_num}.png')
                    shutil.copy(image_path, permanent_path)
                    slide_images.append(permanent_path)
        
        if not slide_images:
            raise Exception("ã‚¹ãƒ©ã‚¤ãƒ‰ç”»åƒã®ç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸ")
        
        return slide_images, temp_dir
        
    except subprocess.TimeoutExpired:
        raise Exception("å¤‰æ›å‡¦ç†ãŒã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã—ã¾ã—ãŸ")
    except Exception as e:
        # ä¸€æ™‚ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
        shutil.rmtree(temp_dir, ignore_errors=True)
        raise e

def create_slide_video_with_narration(slide_image_path, narration_audio_path, duration, output_path):
    """ã‚¹ãƒ©ã‚¤ãƒ‰ç”»åƒã¨ãƒŠãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³éŸ³å£°ã‹ã‚‰å‹•ç”»ã‚’ä½œæˆ"""
    from moviepy import ImageClip
    
    # ã‚¹ãƒ©ã‚¤ãƒ‰ç”»åƒã‹ã‚‰å‹•ç”»ã‚¯ãƒªãƒƒãƒ—ã‚’ä½œæˆ
    slide_clip = ImageClip(slide_image_path, duration=duration)
    
    # éŸ³å£°ã‚’èª­ã¿è¾¼ã¿
    audio = AudioFileClip(narration_audio_path)
    
    # ç”»åƒã‚¯ãƒªãƒƒãƒ—ã«éŸ³å£°ã‚’è¿½åŠ 
    final_clip = slide_clip.with_audio(audio)
    
    # å‡ºåŠ›
    final_clip.write_videofile(
        output_path,
        codec='libx264',
        audio_codec='aac',
        fps=1,  # ã‚¹ãƒ©ã‚¤ãƒ‰ãªã®ã§ä½ã„FPSã§ååˆ†
        ffmpeg_params=['-crf', '18', '-preset', 'fast']
    )
    
    # ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
    slide_clip.close()
    audio.close()
    final_clip.close()
    
    return output_path

def create_text_slide_image(text, title, width=1920, height=1080):
    """ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰ã‚¹ãƒ©ã‚¤ãƒ‰ç”»åƒã‚’ç”Ÿæˆ"""
    # ç©ºã®ç”»åƒã‚’ä½œæˆ
    img = Image.new('RGB', (width, height), color='white')
    draw = ImageDraw.Draw(img)
    
    try:
        # æ—¥æœ¬èªãƒ•ã‚©ãƒ³ãƒˆã‚’èª­ã¿è¾¼ã¿
        title_font = ImageFont.truetype("NotoSansCJK-Regular.ttc", 72)
        text_font = ImageFont.truetype("NotoSansCJK-Regular.ttc", 48)
    except:
        try:
            title_font = ImageFont.load_default(size=72)
            text_font = ImageFont.load_default(size=48)
        except:
            title_font = ImageFont.load_default()
            text_font = ImageFont.load_default()
    
    # ã‚¿ã‚¤ãƒˆãƒ«ã‚’æç”»
    title_bbox = draw.textbbox((0, 0), title, font=title_font)
    title_width = title_bbox[2] - title_bbox[0]
    title_x = (width - title_width) // 2
    draw.text((title_x, 100), title, fill='black', font=title_font)
    
    # ãƒ†ã‚­ã‚¹ãƒˆã‚’æç”»ï¼ˆæ”¹è¡Œå¯¾å¿œï¼‰
    lines = text.split('\n')
    y_offset = 250
    line_height = 60
    
    for line in lines:
        if not line.strip():
            continue
        
        # é•·ã„è¡Œã‚’è‡ªå‹•æ”¹è¡Œ
        words = line.split()
        current_line = ""
        
        for word in words:
            test_line = current_line + word + " "
            bbox = draw.textbbox((0, 0), test_line, font=text_font)
            test_width = bbox[2] - bbox[0]
            
            if test_width > width - 200:  # ãƒãƒ¼ã‚¸ãƒ³ã‚’è€ƒæ…®
                if current_line:
                    # ç¾åœ¨ã®è¡Œã‚’æç”»
                    text_bbox = draw.textbbox((0, 0), current_line, font=text_font)
                    text_width = text_bbox[2] - text_bbox[0]
                    text_x = (width - text_width) // 2
                    draw.text((text_x, y_offset), current_line, fill='black', font=text_font)
                    y_offset += line_height
                current_line = word + " "
            else:
                current_line = test_line
        
        # æ®‹ã‚Šã®ãƒ†ã‚­ã‚¹ãƒˆã‚’æç”»
        if current_line.strip():
            text_bbox = draw.textbbox((0, 0), current_line, font=text_font)
            text_width = text_bbox[2] - text_bbox[0]
            text_x = (width - text_width) // 2
            draw.text((text_x, y_offset), current_line, fill='black', font=text_font)
            y_offset += line_height
    
    # ç”»åƒã‚’ä¿å­˜
    output_path = tempfile.mktemp(suffix='.png')
    img.save(output_path)
    
    return output_path

def combine_videos(video_paths, output_path):
    """è¤‡æ•°ã®å‹•ç”»ã‚’çµåˆã™ã‚‹"""
    clips = []
    try:
        for video_path in video_paths:
            # ãƒ•ã‚¡ã‚¤ãƒ«ã®å­˜åœ¨ç¢ºèª
            if not os.path.exists(video_path):
                raise FileNotFoundError(f"ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {video_path}")
            
            clip = VideoFileClip(video_path)
            clips.append(clip)
        
        # å‹•ç”»ã‚’çµåˆ
        final_clip = concatenate_videoclips(clips, method="compose")
        
        # å‡ºåŠ›ï¼ˆé«˜ç”»è³ªè¨­å®šï¼‰
        final_clip.write_videofile(
            output_path,
            codec='libx264',
            audio_codec='aac',
            bitrate='8000k',
            ffmpeg_params=['-crf', '18', '-preset', 'slow']
        )
        
        return output_path
        
    finally:
        # ãƒªã‚½ãƒ¼ã‚¹ã‚’ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
        for clip in clips:
            try:
                clip.close()
            except:
                pass
        try:
            final_clip.close()
        except:
            pass

# ãƒ¡ã‚¤ãƒ³ã‚¤ãƒ³ã‚¿ãƒ¼face
if tool == "ã‚·ãƒ§ãƒ¼ãƒˆå‹•ç”»å¤‰æ›":
    uploaded_file = st.file_uploader(
        "å‹•ç”»ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„",
        type=['mp4', 'avi', 'mov', 'mkv'],
        help="MP4, AVI, MOV, MKVå½¢å¼ã®å‹•ç”»ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚µãƒãƒ¼ãƒˆã—ã¦ã„ã¾ã™"
    )
elif tool == "å‹•ç”»çµåˆ":
    uploaded_files = st.file_uploader(
        "çµåˆã™ã‚‹å‹•ç”»ãƒ•ã‚¡ã‚¤ãƒ«ã‚’è¤‡æ•°é¸æŠã—ã¦ãã ã•ã„",
        type=['mp4', 'avi', 'mov', 'mkv'],
        accept_multiple_files=True,
        help="MP4, AVI, MOV, MKVå½¢å¼ã®å‹•ç”»ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚µãƒãƒ¼ãƒˆã—ã¦ã„ã¾ã™"
    )
else:  # ãƒ‘ãƒ¯ãƒãƒŠãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³å‹•ç”»
    uploaded_pptx = st.file_uploader(
        "PowerPointãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„",
        type=['pptx', 'ppt'],
        help="PowerPointå½¢å¼ã®ãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆ.pptx, .pptï¼‰ã‚’ã‚µãƒãƒ¼ãƒˆã—ã¦ã„ã¾ã™"
    )

if tool == "ã‚·ãƒ§ãƒ¼ãƒˆå‹•ç”»å¤‰æ›" and uploaded_file is not None:
    # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜
    with tempfile.NamedTemporaryFile(delete=False, suffix='.mp4') as tmp_file:
        tmp_file.write(uploaded_file.read())
        input_video_path = tmp_file.name
    
    # å‹•ç”»æƒ…å ±ã‚’è¡¨ç¤º
    try:
        clip = VideoFileClip(input_video_path)
        col1, col2, col3 = st.columns(3)
        
        with col1:
            st.metric("è§£åƒåº¦", f"{clip.w}x{clip.h}")
        with col2:
            st.metric("æ™‚é–“", f"{clip.duration:.1f}ç§’")
        with col3:
            st.metric("FPS", f"{clip.fps:.1f}")
        
        clip.close()
        
        # ã‚ªãƒ—ã‚·ãƒ§ãƒ³è¨­å®š
        st.subheader("è¨­å®šã‚ªãƒ—ã‚·ãƒ§ãƒ³")
        
        # å‹•ç”»ãƒˆãƒªãƒŸãƒ³ã‚°è¨­å®š
        st.subheader("âœ‚ï¸ å‹•ç”»ãƒˆãƒªãƒŸãƒ³ã‚°è¨­å®š")
        trim_video = st.checkbox("ä¸è¦ãªéƒ¨åˆ†ã‚’å‰Šé™¤ã™ã‚‹")
        
        if trim_video:
            col1, col2 = st.columns(2)
            with col1:
                start_time = st.number_input(
                    "é–‹å§‹æ™‚é–“ï¼ˆç§’ï¼‰", 
                    min_value=0, 
                    max_value=int(clip.duration), 
                    value=0, 
                    step=1,
                    help="ã“ã®æ™‚é–“ã‹ã‚‰å‹•ç”»ã‚’é–‹å§‹ã—ã¾ã™"
                )
            with col2:
                end_time = st.number_input(
                    "çµ‚äº†æ™‚é–“ï¼ˆç§’ï¼‰", 
                    min_value=start_time + 1, 
                    max_value=int(clip.duration), 
                    value=int(clip.duration), 
                    step=1,
                    help="ã“ã®æ™‚é–“ã§å‹•ç”»ã‚’çµ‚äº†ã—ã¾ã™"
                )
            
            if end_time > start_time:
                trimmed_duration = end_time - start_time
                st.info(f"â±ï¸ ãƒˆãƒªãƒŸãƒ³ã‚°å¾Œã®é•·ã•: {trimmed_duration:.1f}ç§’")
            else:
                st.error("çµ‚äº†æ™‚é–“ã¯é–‹å§‹æ™‚é–“ã‚ˆã‚Šå¾Œã«è¨­å®šã—ã¦ãã ã•ã„")
        
        st.subheader("ğŸ“ æ‹¡å¤§å€ç‡è¨­å®š")
        keep_original_size = st.checkbox("å…ƒã®å‹•ç”»ã‚µã‚¤ã‚ºã‚’ç¶­æŒã™ã‚‹", help="ãƒã‚§ãƒƒã‚¯ã™ã‚‹ã¨ã€å‹•ç”»ã¯9:16ã«ãƒªã‚µã‚¤ã‚ºã•ã‚Œãšã€å…ƒã®è§£åƒåº¦ã®ã¾ã¾å‡¦ç†ã•ã‚Œã¾ã™ã€‚")
        
        if not keep_original_size:
            scale_factor = st.slider(
                "å‹•ç”»ã®æ‹¡å¤§å€ç‡",
                min_value=0.5,
                max_value=5.0,
                value=1.0,
                step=0.1,
                help="1.0 = åŸå¯¸å¤§ã€3.0 = 300%æ‹¡å¤§ã€‚å¤§ããã™ã‚‹ã»ã©ã‚ºãƒ¼ãƒ ã‚¤ãƒ³ã•ã‚Œã¾ã™ã€‚"
            )
            
            # å€ç‡ã®èª¬æ˜è¡¨ç¤º
            if scale_factor < 1.0:
                st.info(f"ğŸ“‰ ç¸®å°è¡¨ç¤º: {scale_factor*100:.0f}% (ã‚ˆã‚Šå¤šãã®æ˜ åƒãŒè¦‹ãˆã¾ã™)")
            elif scale_factor == 1.0:
                st.info("ğŸ“Š åŸå¯¸å¤§è¡¨ç¤º: 100% (å…ƒã®å‹•ç”»ã®ã¾ã¾)")
            else:
                st.info(f"ğŸ“ˆ æ‹¡å¤§è¡¨ç¤º: {scale_factor*100:.0f}% (ã‚ºãƒ¼ãƒ ã‚¤ãƒ³åŠ¹æœ)")
        else:
            scale_factor = 1.0 # å…ƒã®ã‚µã‚¤ã‚ºã‚’ç¶­æŒã™ã‚‹å ´åˆã¯ã‚¹ã‚±ãƒ¼ãƒ«ã¯1.0å›ºå®š
        
        # ãƒ†ã‚­ã‚¹ãƒˆã‚ªãƒ¼ãƒãƒ¼ãƒ¬ã‚¤è¨­å®š
        add_text = st.checkbox("ãƒ†ã‚­ã‚¹ãƒˆã‚’è¿½åŠ ã™ã‚‹")
        
        if add_text:
            st.subheader("ãƒ†ãƒ­ãƒƒãƒ—è¨­å®š")
            
            # ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã§ãƒ†ãƒ­ãƒƒãƒ—ãƒªã‚¹ãƒˆã‚’ç®¡ç†
            if 'telops' not in st.session_state:
                st.session_state.telops = []
            
            font_size = st.slider("ãƒ•ã‚©ãƒ³ãƒˆã‚µã‚¤ã‚º", 30, 120, 60)
            
            # ãƒ•ã‚©ãƒ³ãƒˆè‰²ã®é¸æŠ
            st.subheader("ã‚«ãƒ©ãƒ¼è¨­å®š")
            color_options = {
                "ç™½": (255, 255, 255),
                "é»’": (0, 0, 0),
                "èµ¤": (255, 0, 0),
                "é’": (0, 0, 255),
                "ç·‘": (0, 255, 0),
                "é»„": (255, 255, 0),
                "ãƒã‚¼ãƒ³ã‚¿": (255, 0, 255),
                "ã‚·ã‚¢ãƒ³": (0, 255, 255),
                "ã‚ªãƒ¬ãƒ³ã‚¸": (255, 165, 0)
            }
            selected_color_name = st.selectbox("ãƒ•ã‚©ãƒ³ãƒˆè‰²", list(color_options.keys()), index=0)
            selected_color = color_options[selected_color_name]
            
            # æ–°ã—ã„ãƒ†ãƒ­ãƒƒãƒ—ã‚’è¿½åŠ ã™ã‚‹ãƒ•ã‚©ãƒ¼ãƒ 
            with st.expander("æ–°ã—ã„ãƒ†ãƒ­ãƒƒãƒ—ã‚’è¿½åŠ ", expanded=True):
                col1, col2, col3, col4, col5, col6 = st.columns([2, 1, 1, 1, 1, 1])
                
                with col1:
                    new_text = st.text_input("ãƒ†ãƒ­ãƒƒãƒ—ãƒ†ã‚­ã‚¹ãƒˆ", key="new_telop_text")
                with col2:
                    new_position = st.selectbox("ä½ç½®", ["top", "center", "bottom"], key="new_telop_position")
                with col3:
                    new_start = st.number_input("é–‹å§‹(ç§’)", min_value=0, value=0, step=1, key="new_telop_start")
                with col4:
                    new_end = st.number_input("çµ‚äº†(ç§’)", min_value=1, value=5, step=1, key="new_telop_end")
                with col5:
                    new_color_name = st.selectbox("è‰²", list(color_options.keys()), index=0, key="new_telop_color")
                with col6:
                    if st.button("è¿½åŠ ", type="primary"):
                        if new_text.strip():
                            new_telop = {
                                "text": new_text,
                                "position": new_position,
                                "start_time": new_start,
                                "end_time": new_end,
                                "color": color_options[new_color_name]
                            }
                            st.session_state.telops.append(new_telop)
                            st.rerun()
            
            # æ—¢å­˜ã®ãƒ†ãƒ­ãƒƒãƒ—ã‚’è¡¨ç¤ºãƒ»ç·¨é›†
            if st.session_state.telops:
                st.subheader("ç™»éŒ²æ¸ˆã¿ãƒ†ãƒ­ãƒƒãƒ—")
                
                for i, telop in enumerate(st.session_state.telops):
                    with st.container():
                        col1, col2, col3, col4, col5, col6, col7 = st.columns([2, 1, 1, 1, 1, 1, 0.5])
                        
                        with col1:
                            st.text_input(f"ãƒ†ã‚­ã‚¹ãƒˆ {i+1}", value=telop["text"], key=f"telop_text_{i}", disabled=True)
                        with col2:
                            st.text(telop["position"])
                        with col3:
                            st.text(f"{telop['start_time']}ç§’")
                        with col4:
                            st.text(f"{telop['end_time']}ç§’")
                        with col5:
                            duration = telop['end_time'] - telop['start_time']
                            st.text(f"{duration:.1f}ç§’é–“")
                        with col6:
                            # è‰²ã‚’è¡¨ç¤º
                            color = telop.get('color', (255, 255, 255))
                            color_name = next((name for name, rgb in color_options.items() if rgb == color), "ç™½")
                            st.text(color_name)
                        with col7:
                            if st.button("ğŸ—‘ï¸", key=f"delete_telop_{i}", help="å‰Šé™¤"):
                                st.session_state.telops.pop(i)
                                st.rerun()
                
                if st.button("å…¨ã¦ã®ãƒ†ãƒ­ãƒƒãƒ—ã‚’ã‚¯ãƒªã‚¢", type="secondary"):
                    st.session_state.telops = []
                    st.rerun()
        
        # éŸ³å£°åˆæˆè¨­å®šï¼ˆé›¨æ™´ã¯ã†ï¼‰
        st.subheader("ğŸ¤ éŸ³å£°åˆæˆè¨­å®šï¼ˆé›¨æ™´ã¯ã†ï¼‰")
        
        # VOICEVOXã®è¨­å®šæƒ…å ±ã‚’è¡¨ç¤º
        st.info("""
        ğŸ’¡ **VOICEVOXè¨­å®šã«ã¤ã„ã¦ (WSLç’°å¢ƒ)**:
        1. Windowså´ã§VOICEVOXã‚’èµ·å‹•ã—ã¦ãã ã•ã„
        2. VOICEVOXã®è¨­å®šã§ã€Œå¤–éƒ¨ã‹ã‚‰ã®ã‚¢ã‚¯ã‚»ã‚¹ã‚’è¨±å¯ã€ã‚’æœ‰åŠ¹ã«ã—ã¦ãã ã•ã„
        3. Windowsãƒ•ã‚¡ã‚¤ã‚¢ã‚¦ã‚©ãƒ¼ãƒ«ã§ port 50021 ã‚’é–‹æ”¾ã—ã¦ãã ã•ã„
        """)
        
        add_voice = st.checkbox("é›¨æ™´ã¯ã†ã®éŸ³å£°ã‚’è¿½åŠ ã™ã‚‹")
        
        if add_voice:
            # ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã§éŸ³å£°ãƒªã‚¹ãƒˆã‚’ç®¡ç†
            if 'voices' not in st.session_state:
                st.session_state.voices = []
            
            # æ–°ã—ã„éŸ³å£°ã‚’è¿½åŠ ã™ã‚‹ãƒ•ã‚©ãƒ¼ãƒ 
            with st.expander("æ–°ã—ã„éŸ³å£°ã‚’è¿½åŠ ", expanded=True):
                col1, col2, col3, col4 = st.columns([3, 1, 1, 1])
                
                with col1:
                    new_voice_text = st.text_area(
                        "èª­ã¿ä¸Šã’ãƒ†ã‚­ã‚¹ãƒˆ",
                        placeholder="é›¨æ™´ã¯ã†ã«èª­ã¿ä¸Šã’ã¦ã‚‚ã‚‰ã„ãŸã„ãƒ†ã‚­ã‚¹ãƒˆã‚’å…¥åŠ›ã—ã¦ãã ã•ã„",
                        key="new_voice_text",
                        height=100
                    )
                with col2:
                    new_voice_start = st.number_input("é–‹å§‹æ™‚é–“(ç§’)", min_value=0, value=0, step=1, key="new_voice_start")
                with col3:
                    new_voice_volume = st.slider("éŸ³é‡", 0.0, 1.0, 0.8, 0.1, key="new_voice_volume")
                with col4:
                    st.write("") # ã‚¹ãƒšãƒ¼ã‚¹èª¿æ•´
                    if st.button("ğŸ”Š ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼", key="preview_voice"):
                        if new_voice_text.strip():
                            try:
                                with st.spinner("éŸ³å£°ã‚’ç”Ÿæˆä¸­..."):
                                    voice_path = generate_voice_with_voicevox(new_voice_text)
                                    st.audio(voice_path)
                                    os.unlink(voice_path)
                                    st.success("âœ… éŸ³å£°ç”ŸæˆæˆåŠŸï¼")
                            except Exception as e:
                                st.error(f"âŒ éŸ³å£°ç”Ÿæˆã‚¨ãƒ©ãƒ¼: {str(e)}")
                    
                    if st.button("è¿½åŠ ", type="primary", key="add_voice"):
                        if new_voice_text.strip():
                            new_voice = {
                                "text": new_voice_text,
                                "start_time": new_voice_start,
                                "volume": new_voice_volume
                            }
                            st.session_state.voices.append(new_voice)
                            st.rerun()
            
            # æ—¢å­˜ã®éŸ³å£°ã‚’è¡¨ç¤ºãƒ»ç·¨é›†
            if st.session_state.voices:
                st.subheader("ç™»éŒ²æ¸ˆã¿éŸ³å£°")
                
                for i, voice in enumerate(st.session_state.voices):
                    with st.container():
                        col1, col2, col3, col4 = st.columns([3, 1, 1, 0.5])
                        
                        with col1:
                            # ãƒ†ã‚­ã‚¹ãƒˆã‚’1è¡Œã§è¡¨ç¤ºï¼ˆé•·ã„å ´åˆã¯çœç•¥ï¼‰
                            display_text = voice["text"][:50] + "..." if len(voice["text"]) > 50 else voice["text"]
                            st.text_input(f"éŸ³å£° {i+1}", value=display_text, key=f"voice_text_{i}", disabled=True)
                        with col2:
                            st.text(f"{voice['start_time']}ç§’ã‹ã‚‰")
                        with col3:
                            st.text(f"éŸ³é‡: {voice['volume']}")
                        with col4:
                            if st.button("ğŸ—‘ï¸", key=f"delete_voice_{i}", help="å‰Šé™¤"):
                                st.session_state.voices.pop(i)
                                st.rerun()
                
                if st.button("å…¨ã¦ã®éŸ³å£°ã‚’ã‚¯ãƒªã‚¢", type="secondary"):
                    st.session_state.voices = []
                    st.rerun()
        
        # BGMè¨­å®š
        st.subheader("ğŸµ BGMè¨­å®š")
        add_bgm = st.checkbox("BGMã‚’è¿½åŠ ã™ã‚‹")
        
        if add_bgm:
            bgm_file = st.file_uploader(
                "BGMãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰",
                type=['mp3', 'wav', 'aac', 'm4a', 'ogg'],
                help="MP3, WAV, AAC, M4A, OGGå½¢å¼ã®éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚µãƒãƒ¼ãƒˆã—ã¦ã„ã¾ã™"
            )
            
            col1, col2 = st.columns(2)
            with col1:
                bgm_volume = st.slider("BGMéŸ³é‡", 0.0, 1.0, 0.3, 0.1)
            with col2:
                original_volume = st.slider("å…ƒéŸ³å£°éŸ³é‡", 0.0, 1.0, 0.7, 0.1)
            
            loop_bgm = st.checkbox("BGMã‚’ãƒ«ãƒ¼ãƒ—å†ç”Ÿ", value=True)
            
            if bgm_file:
                st.audio(bgm_file)
        
        # å¤‰æ›ãƒœã‚¿ãƒ³
        if st.button("ã‚·ãƒ§ãƒ¼ãƒˆå‹•ç”»ã«å¤‰æ›", type="primary"):
            progress_bar = st.progress(0)
            status_text = st.empty()
            
            try:
                # BGMãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä¸€æ™‚ä¿å­˜
                bgm_path = None
                if add_bgm and bgm_file is not None:
                    with tempfile.NamedTemporaryFile(delete=False, suffix='.mp3') as tmp_bgm:
                        tmp_bgm.write(bgm_file.read())
                        bgm_path = tmp_bgm.name
                
                # Step 1: å‹•ç”»ã‚’ã‚·ãƒ§ãƒ¼ãƒˆå½¢å¼ã«ãƒªã‚µã‚¤ã‚º
                status_text.text("å‹•ç”»ã‚’ãƒªã‚µã‚¤ã‚ºä¸­...")
                progress_bar.progress(20)
                
                with tempfile.NamedTemporaryFile(delete=False, suffix='_resized.mp4') as tmp_resized:
                    resized_video_path = tmp_resized.name
                
                # ãƒˆãƒªãƒŸãƒ³ã‚°ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’è¨­å®š
                trim_start = start_time if trim_video else None
                trim_end = end_time if trim_video else None
                
                resize_video_to_shorts(input_video_path, resized_video_path, scale_factor, trim_start, trim_end, keep_original_size)
                progress_bar.progress(40)
                
                # Step 2: ãƒ†ã‚­ã‚¹ãƒˆã‚’è¿½åŠ ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
                current_video_path = resized_video_path
                if add_text and st.session_state.telops:
                    status_text.text("ãƒ†ã‚­ã‚¹ãƒˆã‚’è¿½åŠ ä¸­...")
                    progress_bar.progress(60)
                    
                    with tempfile.NamedTemporaryFile(delete=False, suffix='_with_text.mp4') as tmp_text:
                        text_video_path = tmp_text.name
                    
                    add_text_to_video(current_video_path, text_video_path, st.session_state.telops, font_size)
                    os.unlink(current_video_path)
                    current_video_path = text_video_path
                
                # Step 3: éŸ³å£°åˆæˆã‚’è¿½åŠ ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
                if add_voice and st.session_state.voices:
                    status_text.text("é›¨æ™´ã¯ã†ã®éŸ³å£°ã‚’ç”Ÿæˆãƒ»è¿½åŠ ä¸­...")
                    progress_bar.progress(60)
                    
                    try:
                        # è¤‡æ•°éŸ³å£°ã‚’å‹•ç”»ã«è¿½åŠ 
                        with tempfile.NamedTemporaryFile(delete=False, suffix='_with_voices.mp4') as tmp_voice:
                            voice_video_path = tmp_voice.name
                        
                        add_multiple_voices_to_video(
                            current_video_path,
                            voice_video_path,
                            st.session_state.voices,
                            1.0  # å…ƒéŸ³å£°éŸ³é‡
                        )
                        
                        os.unlink(current_video_path)
                        current_video_path = voice_video_path
                        
                    except Exception as e:
                        st.warning(f"âš ï¸ éŸ³å£°åˆæˆã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã—ãŸ: {str(e)}")
                
                # Step 4: BGMã‚’è¿½åŠ ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
                if add_bgm and bgm_path:
                    status_text.text("BGMã‚’è¿½åŠ ä¸­...")
                    progress_bar.progress(80)
                    
                    with tempfile.NamedTemporaryFile(delete=False, suffix='_final.mp4') as tmp_final:
                        final_video_path = tmp_final.name
                    
                    add_bgm_to_video(
                        current_video_path, 
                        final_video_path, 
                        bgm_path, 
                        bgm_volume, 
                        original_volume, 
                        loop_bgm
                    )
                    os.unlink(current_video_path)
                    os.unlink(bgm_path)
                else:
                    final_video_path = current_video_path
                
                progress_bar.progress(100)
                status_text.text("å¤‰æ›å®Œäº†ï¼")
                
                # ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼è¡¨ç¤º
                st.subheader("ğŸ“¹ ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼")
                st.video(final_video_path, width=400)
                
                # ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãƒœã‚¿ãƒ³ã‚’è¡¨ç¤º
                with open(final_video_path, 'rb') as file:
                    st.download_button(
                        label="ğŸ“± ã‚·ãƒ§ãƒ¼ãƒˆå‹•ç”»ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
                        data=file.read(),
                        file_name=f"shorts_{uploaded_file.name}",
                        mime="video/mp4"
                    )
                
                # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
                os.unlink(input_video_path)
                os.unlink(final_video_path)
                
                st.success("âœ… å¤‰æ›ãŒå®Œäº†ã—ã¾ã—ãŸï¼ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãƒœã‚¿ãƒ³ã‚’ã‚¯ãƒªãƒƒã‚¯ã—ã¦ä¿å­˜ã—ã¦ãã ã•ã„ã€‚")
                
            except Exception as e:
                st.error(f"âŒ ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}")
                # ã‚¨ãƒ©ãƒ¼æ™‚ã®ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
                try:
                    os.unlink(input_video_path)
                except:
                    pass
    
    except Exception as e:
        st.error(f"âŒ å‹•ç”»ãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸ: {str(e)}")
        os.unlink(input_video_path)

elif tool == "å‹•ç”»çµåˆ" and uploaded_files:
    if len(uploaded_files) < 2:
        st.warning("âš ï¸ 2ã¤ä»¥ä¸Šã®å‹•ç”»ãƒ•ã‚¡ã‚¤ãƒ«ã‚’é¸æŠã—ã¦ãã ã•ã„ã€‚")
    else:
        st.success(f"âœ… {len(uploaded_files)}å€‹ã®å‹•ç”»ãƒ•ã‚¡ã‚¤ãƒ«ãŒé¸æŠã•ã‚Œã¾ã—ãŸã€‚")
        
        # å‹•ç”»æƒ…å ±ã‚’è¡¨ç¤º
        st.subheader("ğŸ“¹ é¸æŠã•ã‚ŒãŸå‹•ç”»")
        total_duration = 0
        
        for i, file in enumerate(uploaded_files):
            # ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä¸€æ™‚ä¿å­˜
            file.seek(0)  # ãƒ•ã‚¡ã‚¤ãƒ«ãƒã‚¤ãƒ³ã‚¿ã‚’å…ˆé ­ã«æˆ»ã™
            temp_path = tempfile.mktemp(suffix=f'_preview_{i}.mp4')
            
            try:
                with open(temp_path, 'wb') as tmp_file:
                    file_bytes = file.getvalue()
                    tmp_file.write(file_bytes)
                    tmp_file.flush()
                    os.fsync(tmp_file.fileno())
                
                # ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºã‚’ç¢ºèª
                if os.path.getsize(temp_path) == 0:
                    st.error(f"âŒ {file.name} ã®ã‚µã‚¤ã‚ºãŒ0ã§ã™")
                    continue
                
            except Exception as e:
                st.error(f"âŒ {file.name}ã®ä¿å­˜ã«å¤±æ•—ã—ã¾ã—ãŸ: {str(e)}")
                continue
            
            try:
                clip = VideoFileClip(temp_path)
                col1, col2, col3, col4 = st.columns(4)
                
                with col1:
                    st.text(f"{i+1}. {file.name}")
                with col2:
                    st.text(f"{clip.w}x{clip.h}")
                with col3:
                    st.text(f"{clip.duration:.1f}ç§’")
                with col4:
                    st.text(f"{clip.fps:.1f} FPS")
                
                total_duration += clip.duration
                clip.close()
                os.unlink(temp_path)
            except Exception as e:
                st.error(f"âŒ {file.name}ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸ: {str(e)}")
                try:
                    os.unlink(temp_path)
                except:
                    pass
        
        st.info(f"ğŸ“Š çµåˆå¾Œã®ç·æ™‚é–“: {total_duration:.1f}ç§’")
        
        # çµåˆãƒœã‚¿ãƒ³
        if st.button("å‹•ç”»ã‚’çµåˆ", type="primary"):
            progress_bar = st.progress(0)
            status_text = st.empty()
            
            try:
                status_text.text("å‹•ç”»ã‚’çµåˆä¸­...")
                progress_bar.progress(20)
                
                # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜
                temp_paths = []
                for i, file in enumerate(uploaded_files):
                    file.seek(0)  # ãƒ•ã‚¡ã‚¤ãƒ«ãƒã‚¤ãƒ³ã‚¿ã‚’å…ˆé ­ã«æˆ»ã™
                    
                    # ä¸€æ„ã®ãƒ•ã‚¡ã‚¤ãƒ«åã‚’ç”Ÿæˆ
                    temp_path = tempfile.mktemp(suffix=f'_video_{i}.mp4')
                    
                    try:
                        with open(temp_path, 'wb') as tmp_file:
                            file_bytes = file.getvalue()
                            tmp_file.write(file_bytes)
                            tmp_file.flush()
                            os.fsync(tmp_file.fileno())
                        
                        # ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºã‚’ç¢ºèª
                        if os.path.getsize(temp_path) == 0:
                            raise ValueError(f"ãƒ•ã‚¡ã‚¤ãƒ« {file.name} ã®ã‚µã‚¤ã‚ºãŒ0ã§ã™")
                        
                        temp_paths.append(temp_path)
                        
                    except Exception as e:
                        st.error(f"âŒ {file.name}ã®ä¿å­˜ã«å¤±æ•—ã—ã¾ã—ãŸ: {str(e)}")
                        # å¤±æ•—ã—ãŸãƒ•ã‚¡ã‚¤ãƒ«ãŒã‚ã‚Œã°ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ã—ã¦çµ‚äº†
                        for path in temp_paths:
                            try:
                                os.unlink(path)
                            except:
                                pass
                        raise
                
                progress_bar.progress(50)
                
                # å‹•ç”»ã‚’çµåˆ
                with tempfile.NamedTemporaryFile(delete=False, suffix='_combined.mp4') as tmp_output:
                    output_path = tmp_output.name
                
                combine_videos(temp_paths, output_path)
                progress_bar.progress(100)
                status_text.text("çµåˆå®Œäº†ï¼")
                
                # ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼è¡¨ç¤º
                st.subheader("ğŸ“¹ çµåˆã•ã‚ŒãŸå‹•ç”»")
                st.video(output_path, width=400)
                
                # ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãƒœã‚¿ãƒ³ã‚’è¡¨ç¤º
                with open(output_path, 'rb') as file:
                    st.download_button(
                        label="ğŸ“± çµåˆå‹•ç”»ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
                        data=file.read(),
                        file_name=f"combined_{len(uploaded_files)}_videos.mp4",
                        mime="video/mp4"
                    )
                
                # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
                for temp_path in temp_paths:
                    os.unlink(temp_path)
                os.unlink(output_path)
                
                st.success("âœ… çµåˆãŒå®Œäº†ã—ã¾ã—ãŸï¼ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãƒœã‚¿ãƒ³ã‚’ã‚¯ãƒªãƒƒã‚¯ã—ã¦ä¿å­˜ã—ã¦ãã ã•ã„ã€‚")
                
            except Exception as e:
                st.error(f"âŒ ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}")
                # ã‚¨ãƒ©ãƒ¼æ™‚ã®ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
                for temp_path in temp_paths:
                    try:
                        os.unlink(temp_path)
                    except:
                        pass

elif tool == "ãƒ‘ãƒ¯ãƒãƒŠãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³å‹•ç”»" and uploaded_pptx is not None:
    try:
        # PowerPointãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ã‚¹ãƒ©ã‚¤ãƒ‰ã¨ãƒãƒ¼ãƒˆã‚’æŠ½å‡º
        with st.spinner("PowerPointãƒ•ã‚¡ã‚¤ãƒ«ã‚’è§£æä¸­..."):
            slides_data = extract_slides_and_notes(uploaded_pptx)
        
        if not slides_data:
            st.error("âŒ ã‚¹ãƒ©ã‚¤ãƒ‰ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
        else:
            st.success(f"âœ… {len(slides_data)}æšã®ã‚¹ãƒ©ã‚¤ãƒ‰ãŒè¦‹ã¤ã‹ã‚Šã¾ã—ãŸã€‚")
            
            # ã‚¹ãƒ©ã‚¤ãƒ‰æƒ…å ±ã‚’è¡¨ç¤º
            st.subheader("ğŸ“‹ æŠ½å‡ºã•ã‚ŒãŸã‚¹ãƒ©ã‚¤ãƒ‰æƒ…å ±")
            
            for i, slide in enumerate(slides_data):
                with st.expander(f"ã‚¹ãƒ©ã‚¤ãƒ‰ {slide['slide_number']}: {slide['slide_text'][:50]}..."):
                    col1, col2 = st.columns(2)
                    
                    with col1:
                        st.markdown("**ã‚¹ãƒ©ã‚¤ãƒ‰å†…å®¹:**")
                        st.text_area("", value=slide['slide_text'], height=100, key=f"slide_text_{i}", disabled=True)
                    
                    with col2:
                        st.markdown("**ãƒãƒ¼ãƒˆï¼ˆèª­ã¿ä¸Šã’å†…å®¹ï¼‰:**")
                        if slide['notes_text']:
                            st.text_area("", value=slide['notes_text'], height=100, key=f"notes_text_{i}", disabled=True)
                        else:
                            st.info("ãƒãƒ¼ãƒˆãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“")
            
            # è¨­å®šã‚ªãƒ—ã‚·ãƒ§ãƒ³
            st.subheader("ğŸ›ï¸ å‹•ç”»è¨­å®š")
            
            col1, col2 = st.columns(2)
            
            with col1:
                slide_duration = st.slider(
                    "å„ã‚¹ãƒ©ã‚¤ãƒ‰ã®è¡¨ç¤ºæ™‚é–“ï¼ˆç§’ï¼‰",
                    min_value=3,
                    max_value=30,
                    value=10,
                    help="ãƒãƒ¼ãƒˆãŒã‚ã‚‹å ´åˆã¯éŸ³å£°ã®é•·ã•ã«è‡ªå‹•èª¿æ•´ã•ã‚Œã¾ã™"
                )
            
            with col2:
                voice_speed = st.slider(
                    "èª­ã¿ä¸Šã’é€Ÿåº¦",
                    min_value=0.5,
                    max_value=2.0,
                    value=1.0,
                    step=0.1,
                    help="éŸ³å£°ã®èª­ã¿ä¸Šã’é€Ÿåº¦ã‚’èª¿æ•´ã—ã¾ã™"
                )
            
            # å¤‰æ›ãƒœã‚¿ãƒ³
            if st.button("ãƒŠãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³å‹•ç”»ã‚’ä½œæˆ", type="primary"):
                progress_bar = st.progress(0)
                status_text = st.empty()
                
                try:
                    # Step 1: PowerPointã‚¹ãƒ©ã‚¤ãƒ‰ã‚’ç”»åƒã«å¤‰æ›
                    status_text.text("ã‚¹ãƒ©ã‚¤ãƒ‰ã‚’ç”»åƒã«å¤‰æ›ä¸­...")
                    progress_bar.progress(10)
                    
                    # PowerPointãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰å®Ÿéš›ã®ã‚¹ãƒ©ã‚¤ãƒ‰ç”»åƒã‚’æŠ½å‡º
                    try:
                        slide_image_paths, temp_conversion_dir = create_slide_images_from_pptx(uploaded_pptx)
                        use_real_slides = True
                        st.info(f"âœ… {len(slide_image_paths)}æšã®ã‚¹ãƒ©ã‚¤ãƒ‰ç”»åƒã‚’æŠ½å‡ºã—ã¾ã—ãŸ")
                    except Exception as e:
                        st.warning(f"âš ï¸ ã‚¹ãƒ©ã‚¤ãƒ‰ç”»åƒã®æŠ½å‡ºã«å¤±æ•—ã—ã¾ã—ãŸã€‚ãƒ†ã‚­ã‚¹ãƒˆãƒ™ãƒ¼ã‚¹ã®ã‚¹ãƒ©ã‚¤ãƒ‰ã‚’ä½¿ç”¨ã—ã¾ã™: {str(e)}")
                        slide_image_paths = []
                        use_real_slides = False
                    
                    slide_videos = []
                    temp_files = []
                    
                    for i, slide in enumerate(slides_data):
                        progress = 10 + (i / len(slides_data)) * 80
                        progress_bar.progress(int(progress))
                        status_text.text(f"ã‚¹ãƒ©ã‚¤ãƒ‰ {i+1}/{len(slides_data)} ã‚’å‡¦ç†ä¸­...")
                        
                        # ã‚¹ãƒ©ã‚¤ãƒ‰ç”»åƒã‚’å–å¾—ï¼ˆå®Ÿéš›ã®ã‚¹ãƒ©ã‚¤ãƒ‰ã¾ãŸã¯ãƒ†ã‚­ã‚¹ãƒˆãƒ™ãƒ¼ã‚¹ï¼‰
                        if use_real_slides and i < len(slide_image_paths):
                            slide_image_path = slide_image_paths[i]
                        else:
                            # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: ãƒ†ã‚­ã‚¹ãƒˆãƒ™ãƒ¼ã‚¹ã®ã‚¹ãƒ©ã‚¤ãƒ‰ç”Ÿæˆ
                            slide_image_path = create_text_slide_image(
                                slide['slide_text'], 
                                f"ã‚¹ãƒ©ã‚¤ãƒ‰ {slide['slide_number']}"
                            )
                            temp_files.append(slide_image_path)
                        
                        # ãƒŠãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³éŸ³å£°ã‚’ç”Ÿæˆï¼ˆãƒãƒ¼ãƒˆãŒã‚ã‚‹å ´åˆï¼‰
                        if slide['notes_text'].strip():
                            try:
                                voice_path = generate_voice_with_voicevox(slide['notes_text'])
                                temp_files.append(voice_path)
                                
                                # éŸ³å£°ã®é•·ã•ã‚’å–å¾—
                                audio_clip = AudioFileClip(voice_path)
                                duration = max(audio_clip.duration, 3)  # æœ€ä½3ç§’
                                audio_clip.close()
                                
                            except Exception as e:
                                st.warning(f"âš ï¸ ã‚¹ãƒ©ã‚¤ãƒ‰{i+1}ã®éŸ³å£°ç”Ÿæˆã«å¤±æ•—: {str(e)}")
                                voice_path = None
                                duration = slide_duration
                        else:
                            voice_path = None
                            duration = slide_duration
                        
                        # ã‚¹ãƒ©ã‚¤ãƒ‰å‹•ç”»ã‚’ä½œæˆ
                        slide_video_path = tempfile.mktemp(suffix=f'_slide_video_{i}.mp4')
                        temp_files.append(slide_video_path)
                        
                        if voice_path:
                            create_slide_video_with_narration(slide_image_path, voice_path, duration, slide_video_path)
                        else:
                            # éŸ³å£°ãªã—ã®å ´åˆ
                            from moviepy import ImageClip
                            clip = ImageClip(slide_image_path, duration=duration)
                            clip.write_videofile(
                                slide_video_path,
                                codec='libx264',
                                fps=1,
                                ffmpeg_params=['-crf', '18', '-preset', 'fast']
                            )
                            clip.close()
                        
                        slide_videos.append(slide_video_path)
                    
                    # Step 2: å…¨ã‚¹ãƒ©ã‚¤ãƒ‰å‹•ç”»ã‚’çµåˆ
                    status_text.text("å‹•ç”»ã‚’çµåˆä¸­...")
                    progress_bar.progress(90)
                    
                    final_output_path = tempfile.mktemp(suffix='_presentation_video.mp4')
                    temp_files.append(final_output_path)
                    
                    combine_videos(slide_videos, final_output_path)
                    
                    progress_bar.progress(100)
                    status_text.text("å¤‰æ›å®Œäº†ï¼")
                    
                    # ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼è¡¨ç¤º
                    st.subheader("ğŸ“¹ ä½œæˆã•ã‚ŒãŸãƒŠãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³å‹•ç”»")
                    st.video(final_output_path, width=600)
                    
                    # ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãƒœã‚¿ãƒ³ã‚’è¡¨ç¤º
                    with open(final_output_path, 'rb') as file:
                        st.download_button(
                            label="ğŸ“± ãƒŠãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³å‹•ç”»ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
                            data=file.read(),
                            file_name=f"presentation_{uploaded_pptx.name.split('.')[0]}.mp4",
                            mime="video/mp4"
                        )
                    
                    st.success("âœ… å‹•ç”»å¤‰æ›ãŒå®Œäº†ã—ã¾ã—ãŸï¼ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãƒœã‚¿ãƒ³ã‚’ã‚¯ãƒªãƒƒã‚¯ã—ã¦ä¿å­˜ã—ã¦ãã ã•ã„ã€‚")
                    
                except Exception as e:
                    st.error(f"âŒ ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}")
                finally:
                    # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
                    for temp_file in temp_files:
                        try:
                            os.unlink(temp_file)
                        except:
                            pass
                    
                    # ã‚¹ãƒ©ã‚¤ãƒ‰ç”»åƒã®ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã‚‚ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
                    if use_real_slides:
                        for slide_image in slide_image_paths:
                            try:
                                os.unlink(slide_image)
                            except:
                                pass
                        try:
                            import shutil
                            shutil.rmtree(temp_conversion_dir, ignore_errors=True)
                        except:
                            pass
    
    except Exception as e:
        st.error(f"âŒ PowerPointãƒ•ã‚¡ã‚¤ãƒ«ã®è§£æã«å¤±æ•—ã—ã¾ã—ãŸ: {str(e)}")

# ä½¿ç”¨æ–¹æ³•ã®èª¬æ˜
if tool == "ã‚·ãƒ§ãƒ¼ãƒˆå‹•ç”»å¤‰æ›":
    st.sidebar.header("ğŸ“– ä½¿ç”¨æ–¹æ³•")
    st.sidebar.markdown("""
    1. **å‹•ç”»ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰**: MP4ã€AVIã€MOVã€MKVå½¢å¼ã®å‹•ç”»ãƒ•ã‚¡ã‚¤ãƒ«ã‚’é¸æŠ
    2. **ãƒ†ã‚­ã‚¹ãƒˆè¿½åŠ ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰**: ãƒ†ãƒ­ãƒƒãƒ—ã‚’è¿½åŠ ã—ãŸã„å ´åˆã¯ãƒã‚§ãƒƒã‚¯
    3. **å¤‰æ›å®Ÿè¡Œ**: ã€Œã‚·ãƒ§ãƒ¼ãƒˆå‹•ç”»ã«å¤‰æ›ã€ãƒœã‚¿ãƒ³ã‚’ã‚¯ãƒªãƒƒã‚¯
    4. **ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰**: å¤‰æ›å®Œäº†å¾Œã€ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãƒœã‚¿ãƒ³ã§ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä¿å­˜
    
    **YouTubeã‚·ãƒ§ãƒ¼ãƒˆä»•æ§˜**:
    - è§£åƒåº¦: 1080x1920 (9:16)
    - æœ€å¤§æ™‚é–“: 60ç§’
    """)
elif tool == "å‹•ç”»çµåˆ":
    st.sidebar.header("ğŸ“– ä½¿ç”¨æ–¹æ³•")
    st.sidebar.markdown("""
    1. **å‹•ç”»ã‚’è¤‡æ•°é¸æŠ**: MP4ã€AVIã€MOVã€MKVå½¢å¼ã®å‹•ç”»ãƒ•ã‚¡ã‚¤ãƒ«ã‚’2ã¤ä»¥ä¸Šé¸æŠ
    2. **çµåˆå®Ÿè¡Œ**: ã€Œå‹•ç”»ã‚’çµåˆã€ãƒœã‚¿ãƒ³ã‚’ã‚¯ãƒªãƒƒã‚¯
    3. **ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰**: çµåˆå®Œäº†å¾Œã€ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãƒœã‚¿ãƒ³ã§ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä¿å­˜
    
    **æ³¨æ„äº‹é …**:
    - å‹•ç”»ã¯é¸æŠã—ãŸé †ç•ªã§çµåˆã•ã‚Œã¾ã™
    - ç•°ãªã‚‹è§£åƒåº¦ã®å‹•ç”»ã‚‚çµåˆå¯èƒ½ã§ã™
    """)
else:  # ãƒ‘ãƒ¯ãƒãƒŠãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³å‹•ç”»
    st.sidebar.header("ğŸ“– ä½¿ç”¨æ–¹æ³•")
    st.sidebar.markdown("""
    1. **PowerPointãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰**: .pptx, .pptå½¢å¼ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’é¸æŠ
    2. **ã‚¹ãƒ©ã‚¤ãƒ‰ç¢ºèª**: æŠ½å‡ºã•ã‚ŒãŸã‚¹ãƒ©ã‚¤ãƒ‰å†…å®¹ã¨ãƒãƒ¼ãƒˆã‚’ç¢ºèª
    3. **è¨­å®šèª¿æ•´**: ã‚¹ãƒ©ã‚¤ãƒ‰è¡¨ç¤ºæ™‚é–“ã¨èª­ã¿ä¸Šã’é€Ÿåº¦ã‚’èª¿æ•´
    4. **å¤‰æ›å®Ÿè¡Œ**: ã€ŒãƒŠãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³å‹•ç”»ã‚’ä½œæˆã€ãƒœã‚¿ãƒ³ã‚’ã‚¯ãƒªãƒƒã‚¯
    5. **ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰**: å®Œæˆã—ãŸå‹•ç”»ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
    
    **é‡è¦**:
    - ã‚¹ãƒ”ãƒ¼ã‚«ãƒ¼ãƒãƒ¼ãƒˆãŒèª­ã¿ä¸Šã’ã‚‰ã‚Œã¾ã™
    - ãƒãƒ¼ãƒˆãŒãªã„ã‚¹ãƒ©ã‚¤ãƒ‰ã¯è¨­å®šæ™‚é–“ã§è¡¨ç¤ºã•ã‚Œã¾ã™
    """)

st.sidebar.header("â„¹ï¸ å¯¾å¿œå½¢å¼")
if tool == "ã‚·ãƒ§ãƒ¼ãƒˆå‹•ç”»å¤‰æ›" or tool == "å‹•ç”»çµåˆ":
    st.sidebar.markdown("""
    **å‹•ç”»å…¥åŠ›å½¢å¼**:
    - MP4
    - AVI
    - MOV
    - MKV

    **BGMå…¥åŠ›å½¢å¼**:
    - MP3
    - WAV
    - AAC
    - M4A
    - OGG

    **å‡ºåŠ›å½¢å¼**:
    - MP4 (H.264)
    """)
else:  # ãƒ‘ãƒ¯ãƒãƒŠãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³å‹•ç”»
    st.sidebar.markdown("""
    **PowerPointå…¥åŠ›å½¢å¼**:
    - PPTX
    - PPT

    **å‡ºåŠ›å½¢å¼**:
    - MP4 (H.264)
    - è§£åƒåº¦: 1920x1080 (16:9)
    - éŸ³å£°: AAC (VOICEVOX)
    """)